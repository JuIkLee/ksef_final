{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "205b0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from tensorflow.python.keras.utils import get_custom_objects\n",
    "import efficientnet.tfkeras as efn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7cd819",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/ODIR-5K/data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ocular-disease-recognition dataset\u001b[39;00m\n\u001b[0;32m     15\u001b[0m OCU_IMG_ROOT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/ODIR-5K/Training Images/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 16\u001b[0m ocu_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/ODIR-5K/data.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\test_envs\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\test_envs\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\test_envs\\lib\\site-packages\\pandas\\io\\excel\\_base.py:483\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    482\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 483\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    488\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\test_envs\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1629\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1627\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1629\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1634\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1635\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1636\u001b[0m         )\n",
      "File \u001b[1;32m~\\.conda\\envs\\test_envs\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1502\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1500\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1502\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1505\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1506\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\test_envs\\lib\\site-packages\\pandas\\io\\common.py:866\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    862\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    867\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/ODIR-5K/data.xlsx'"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "IMG_HEIGHT = 192\n",
    "IMG_WIDTH = 256\n",
    "\n",
    "# cataract dataset\n",
    "IMG_ROOT = './data/dataset/'\n",
    "IMG_DIR = [IMG_ROOT+'1_normal', \n",
    "           IMG_ROOT+'2_cataract', \n",
    "           IMG_ROOT+'2_glaucoma', \n",
    "           IMG_ROOT+'3_retina_disease']\n",
    "\n",
    "# ocular-disease-recognition dataset\n",
    "OCU_IMG_ROOT = './data/ODIR-5K/Training Images/'\n",
    "ocu_df = pd.read_excel('./data/ODIR-5K/data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = pd.DataFrame(0, \n",
    "                  columns=['paths', \n",
    "                           'glaucoma'],\n",
    "                  index=range(601))\n",
    "\n",
    "filepaths = glob.glob(IMG_ROOT + '*/*')\n",
    "\n",
    "\n",
    "for i, filepath in enumerate(filepaths):\n",
    "    filepath = os.path.split(filepath)\n",
    "    cat_df.iloc[i, 0] = filepath[0] + '/' + filepath[1]\n",
    "    \n",
    "    if filepath[0] == IMG_DIR[0]:    # normal\n",
    "        cat_df.iloc[i, 1] = 0\n",
    "    elif filepath[0] == IMG_DIR[2]:  # cataract\n",
    "        cat_df.iloc[i, 1] = 2\n",
    "    elif filepath[0] == IMG_DIR[1]:  # glaucoma\n",
    "        cat_df.iloc[i, 1] = 1\n",
    "    elif filepath[0] == IMG_DIR[3]:  # retine_disease\n",
    "        cat_df.iloc[i, 1] = 3\n",
    "        \n",
    "# only sample normal and cataract        \n",
    "cat_df = cat_df.query('0 <= glaucoma < 2')\n",
    "cat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f31e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of normal and glaucoma images')\n",
    "print(cat_df['glaucoma'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6bbec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_cataract_mentioned(text):\n",
    "    if 'glaucoma' in text:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "ocu_df['left_eye_glaucoma'] = ocu_df['Left-Diagnostic Keywords']\\\n",
    "                                 .apply(lambda x: has_cataract_mentioned(x))\n",
    "ocu_df['right_eye_glaucoma'] = ocu_df['Right-Diagnostic Keywords']\\\n",
    "                                 .apply(lambda x: has_cataract_mentioned(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64719139",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_df = ocu_df.loc[:, ['Left-Fundus', 'left_eye_glaucoma']]\\\n",
    "        .rename(columns={'left_eye_glaucoma':'glaucoma'})\n",
    "le_df['paths'] = OCU_IMG_ROOT + le_df['Left-Fundus']\n",
    "le_df = le_df.drop('Left-Fundus', axis=1)\n",
    "\n",
    "\n",
    "re_df = ocu_df.loc[:, ['Right-Fundus', 'right_eye_glaucoma']]\\\n",
    "        .rename(columns={'right_eye_glaucoma':'glaucoma'})\n",
    "re_df['paths'] = OCU_IMG_ROOT + re_df['Right-Fundus']\n",
    "re_df = re_df.drop('Right-Fundus', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b403a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a0a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of left eye images')\n",
    "print(le_df['glaucoma'].value_counts())\n",
    "print('\\nNumber of right eye images')\n",
    "print(re_df['glaucoma'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(df):\n",
    "    df = pd.concat([\n",
    "        df.query('glaucoma==1'),\n",
    "        df.query('glaucoma==0').sample(sum(df['glaucoma']), \n",
    "                                       random_state=SEED)\n",
    "    ])\n",
    "    return df\n",
    "\n",
    "\n",
    "le_df = downsample(le_df)\n",
    "re_df = downsample(re_df)\n",
    "\n",
    "print('Number of left eye images')\n",
    "print(le_df['glaucoma'].value_counts())\n",
    "print('\\nNumber of right eye images')\n",
    "print(re_df['glaucoma'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocu_df = pd.concat([le_df, re_df])\n",
    "ocu_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([cat_df, ocu_df], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, \n",
    "                                     test_size=0.2, \n",
    "                                     random_state=SEED, \n",
    "                                     stratify=df['glaucoma'])\n",
    "\n",
    "train_df, val_df = train_test_split(train_df,\n",
    "                                    test_size=0.15,\n",
    "                                    random_state=SEED,\n",
    "                                    stratify=train_df['glaucoma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(df, img_width, img_height):\n",
    "    imgs = []\n",
    "    for path in tqdm(df['paths']):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (img_width, img_height))\n",
    "        imgs.append(img)\n",
    "        \n",
    "    imgs = np.array(imgs, dtype='float32')\n",
    "    df = pd.get_dummies(df['glaucoma'])\n",
    "    return imgs, df\n",
    "\n",
    "\n",
    "train_imgs, train_df = create_datasets(train_df, IMG_WIDTH, IMG_HEIGHT)\n",
    "val_imgs, val_df = create_datasets(val_df, IMG_WIDTH, IMG_HEIGHT)\n",
    "test_imgs, test_df = create_datasets(test_df, IMG_WIDTH, IMG_HEIGHT)\n",
    "\n",
    "train_imgs = train_imgs / 255.0\n",
    "val_imgs = val_imgs / 255.0\n",
    "test_imgs = test_imgs / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3188e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 25 sheets of image data for training\n",
    "\n",
    "f, ax = plt.subplots(5, 5, figsize=(15,15))\n",
    "norm_list = list(train_df[0][:25])\n",
    "for i, img in enumerate(train_imgs[:25]):\n",
    "    ax[i//5, i%5].imshow(img)\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    if norm_list[i] == 1:\n",
    "        ax[i//5, i%5].set_title('TrainData: Normal')\n",
    "    else:\n",
    "        ax[i//5, i%5].set_title('TrainData: glaucoma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6024da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 25 sheets of image data for Test\n",
    "f, ax = plt.subplots(5, 5, figsize=(15,15))\n",
    "norm_list = list(test_df[0][:25])\n",
    "for i, img in enumerate(test_imgs[:25]):\n",
    "    ax[i//5, i%5].imshow(img)\n",
    "    ax[i//5, i%5].axis('off')\n",
    "    if norm_list[i] == 1:\n",
    "        ax[i//5, i%5].set_title('TestData: Normal')\n",
    "    else:\n",
    "        ax[i//5, i%5].set_title('TestData: glaucoma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944327f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(img_height, img_width, n):\n",
    "    inp = Input(shape=(img_height,img_width,n))\n",
    "    efnet = efn.EfficientNetB0(\n",
    "        input_shape=(img_height,img_width,n), \n",
    "        weights='imagenet', \n",
    "        include_top=False\n",
    "    )\n",
    "    x = efnet(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(2, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.000003)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.01)\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5009cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = ImageDataGenerator(horizontal_flip=True, \n",
    "                               height_shift_range=0.1,\n",
    "                               fill_mode='reflect') \n",
    "\n",
    "\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, \n",
    "                                               verbose=1, \n",
    "                                               restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aaea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(generator.flow(train_imgs, \n",
    "                                   train_df,\n",
    "                                   batch_size=BATCH_SIZE), \n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch=len(train_imgs)/BATCH_SIZE,\n",
    "                    callbacks=[es_callback, reduce_lr],\n",
    "                    validation_data=(val_imgs, val_df))\n",
    "\n",
    "\n",
    "pd.DataFrame(history.history)[['accuracy', 'val_accuracy']].plot()\n",
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5babed3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(test_imgs, test_df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_imgs, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0801d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804eba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee9f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e18e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
